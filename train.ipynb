{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb68d492",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aksingh/miniconda3/envs/meta-learned-lines/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset glue (/home/aksingh/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 587.90it/s]\n",
      "Found cached dataset glue (/home/aksingh/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:00<00:00, 37.73it/s]\n",
      "Found cached dataset glue (/home/aksingh/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 460.56it/s]\n",
      "Found cached dataset glue (/home/aksingh/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 55.10it/s]\n",
      "Found cached dataset glue (/home/aksingh/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 16.05it/s]\n",
      "Found cached dataset glue (/home/aksingh/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 476.81it/s]\n",
      "Found cached dataset glue (/home/aksingh/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 185.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from training_datasets.GLUEMetaDataset import GLUEMetaDataset\n",
    "from samplers.FewShotEpisodeSampler import FewShotEpisodeSampler\n",
    "from samplers.FewShotEpisodeBatchSampler import FewShotEpisodeBatchSampler\n",
    "import torch.utils.data as data\n",
    "\n",
    "meta_ds = GLUEMetaDataset(k=8, numTasks=2, length=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d24829a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_protomaml_sampler = FewShotEpisodeBatchSampler(meta_ds, kShot=4, batchSize=2)\n",
    "\n",
    "train_protomaml_loader = data.DataLoader(\n",
    "    meta_ds, batch_sampler=train_protomaml_sampler, collate_fn=train_protomaml_sampler.getCollateFunction(), num_workers=4)\n",
    "\n",
    "# for i in range(1):\n",
    "#     batch = next(iter(train_protomaml_loader))\n",
    "#     for episode_i in range(len(batch[0])):\n",
    "#         data, labels = batch[0][episode_i], batch[1][episode_i]\n",
    "#         supportSet, supportLabels = data[0:len(data)//2], labels[0:len(data)//2] \n",
    "#         print(supportLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b300d2f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# episodes = []\n",
    "# for i in range(1):\n",
    "#     episodes.append(gm_ds.getTask())\n",
    "# for i in range(len(episodes)):\n",
    "#     classes = len(set(episodes[i][1].tolist()))\n",
    "#     # print(classes)\n",
    "#     print(episodes[i][0], episodes[i][1], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec3922a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from training.models.ProtoFOMAML import ProtoFOMAML\n",
    "\n",
    "# pfomaml = ProtoFOMAML(outerLR=5e-4, innerLR=1e-3, outputLR=1e-2, steps=5, batchSize=16, warmupSteps=0)\n",
    "# pfomaml.training_step(next(iter(train_protomaml_loader)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3670cc53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from samplers.FewShotValidationEpisodeBatchSampler import FewShotValidationEpisodeBatchSampler\n",
    "from samplers.FewShotValidationEpisodeSampler import FewShotValidationEpisodeSampler\n",
    "from validation_datasets.ValidationDataset import ValidationDataset\n",
    "import torch.utils.data as data\n",
    "\n",
    "ds = ValidationDataset()\n",
    "\n",
    "val_protomaml_sampler = FewShotValidationEpisodeBatchSampler(ds, kShot=8)\n",
    "val_protomaml_loader = data.DataLoader(\n",
    "    ds, batch_sampler=val_protomaml_sampler, collate_fn=val_protomaml_sampler.getCollateFunction(), num_workers=1\n",
    ")\n",
    "\n",
    "for i in range(1):\n",
    "    batch = next(iter(val_protomaml_loader))\n",
    "    for episode_i in range(len(batch[0])):\n",
    "        data, labels = batch[0][episode_i], batch[1][episode_i]\n",
    "        supportSet, supportLabels = data[0:len(data)//2], labels[0:len(data)//2] \n",
    "#         print(supportSet)\n",
    "#         print(supportLabels)\n",
    "#         print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ef372a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 11:22:58.816879: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-03 11:22:58.829669: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-03 11:22:58.894427: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-03 11:22:58.894988: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-03 11:22:59.595042: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from training.models.ProtoFOMAML import ProtoFOMAML\n",
    "from training.models.FOMAML import FOMAML\n",
    "from training.models.ProtoNet import ProtoNet\n",
    "from training.models.Reptile import Reptile\n",
    "\n",
    "# pfomaml = ProtoFOMAML(outerLR=5e-4, innerLR=1e-3, outputLR=1e-2, steps=5, batchSize=16, warmupSteps=0)\n",
    "# pfomaml.validation_step(next(iter(val_protomaml_loader)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0cb485",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model /home/aksingh/Downloads/version_8230128/checkpoints/working.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "\n",
      "  | Name        | Type               | Params\n",
      "---------------------------------------------------\n",
      "0 | metaLearner | PrototypeMetaModel | 108 M \n",
      "---------------------------------------------------\n",
      "14.2 M    Trainable params\n",
      "94.1 M    Non-trainable params\n",
      "108 M     Total params\n",
      "433.241   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training FOMAML with parameters \"batchSize\":   4\n",
      "\"innerLR\":     0.001\n",
      "\"outerLR\":     5e-05\n",
      "\"outputLR\":    0.001\n",
      "\"steps\":       5\n",
      "\"warmupSteps\": 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aksingh/miniconda3/envs/meta-learned-lines/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels in the episode are 2 and lines are 1\n",
      "inner loop training loss is 0.7114419937133789 and accuracy is 0.5\n",
      "inner loop training loss is 0.7091721296310425 and accuracy is 0.5\n",
      "inner loop training loss is 0.7069917321205139 and accuracy is 0.5\n",
      "inner loop training loss is 0.7048956155776978 and accuracy is 0.5\n",
      "inner loop training loss is 0.7028789520263672 and accuracy is 0.5\n",
      "outer loop episodic validation accuracy is 0.625 and loss is 0.6662566661834717\n",
      "Number of labels in the episode are 3 and lines are 1\n",
      "inner loop training loss is 1.0620187520980835 and accuracy is 0.5\n",
      "inner loop training loss is 1.0596054792404175 and accuracy is 0.5\n",
      "inner loop training loss is 1.0572313070297241 and accuracy is 0.5\n",
      "inner loop training loss is 1.0548949241638184 and accuracy is 0.5\n",
      "inner loop training loss is 1.0525954961776733 and accuracy is 0.5\n",
      "outer loop episodic validation accuracy is 0.5416666666666666 and loss is 1.0790377855300903\n",
      "Number of labels in the episode are 3 and lines are 1\n",
      "inner loop training loss is 1.1629303693771362 and accuracy is 0.375\n",
      "inner loop training loss is 1.1576465368270874 and accuracy is 0.375\n",
      "inner loop training loss is 1.152530312538147 and accuracy is 0.375\n",
      "inner loop training loss is 1.1475766897201538 and accuracy is 0.375\n",
      "inner loop training loss is 1.1427799463272095 and accuracy is 0.375\n",
      "outer loop episodic validation accuracy is 0.3333333333333333 and loss is 1.143522024154663\n",
      "Number of labels in the episode are 3 and lines are 1\n",
      "inner loop training loss is 1.1699862480163574 and accuracy is 0.25\n",
      "inner loop training loss is 1.1658481359481812 and accuracy is 0.25\n",
      "inner loop training loss is 1.161795973777771 and accuracy is 0.25\n",
      "inner loop training loss is 1.1578267812728882 and accuracy is 0.25\n",
      "inner loop training loss is 1.1539376974105835 and accuracy is 0.20833333333333334\n",
      "outer loop episodic validation accuracy is 0.25 and loss is 1.0958350896835327\n",
      "Number of labels in the episode are 3 and lines are 1\n"
     ]
    }
   ],
   "source": [
    "from training.trainer import train_model\n",
    "import torch.utils.data as data\n",
    "\n",
    "protomaml_model = train_model(\n",
    "    FOMAML,\n",
    "    train_loader=train_protomaml_loader,\n",
    "    val_loader=val_protomaml_loader,\n",
    "    outerLR=5e-5, innerLR=1e-3, outputLR=1e-3, steps=5, batchSize=4, warmupSteps=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc0e315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from training_datasets.GLUEMetaDataset import GLUEMetaDataset\n",
    "# from samplers.FewShotEpisodeSampler import FewShotEpisodeSampler\n",
    "# from samplers.FewShotEpisodeBatchSampler import FewShotEpisodeBatchSampler\n",
    "# import torch.utils.data as data\n",
    "\n",
    "# meta_ds = GLUEMetaDataset(k=4,numTasks=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94698b12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from training.models.ProtoNet import ProtoNet\n",
    "# import torch.utils.data as data\n",
    "# from training_datasets.GLUEMetaDataset import GLUEMetaDataset\n",
    "# from training.trainer import train_model\n",
    "\n",
    "# from samplers.FewShotValidationEpisodeBatchSampler import FewShotValidationEpisodeBatchSampler\n",
    "# from samplers.FewShotValidationEpisodeSampler import FewShotValidationEpisodeSampler\n",
    "# from validation_datasets.ValidationDataset import ValidationDataset\n",
    "# from validation_datasets.GLUEMetaValidationDataset import GLUEMetaValidationDataset\n",
    "# import torch.utils.data as data\n",
    "\n",
    "# ds = ValidationDataset()\n",
    "\n",
    "# val_protomaml_sampler = FewShotValidationEpisodeBatchSampler(ds, kShot=4)\n",
    "# val_protomaml_loader = data.DataLoader(\n",
    "#     ds, batch_sampler=val_protomaml_sampler, collate_fn=val_protomaml_sampler.getCollateFunction(), num_workers=1\n",
    "# )\n",
    "\n",
    "# validation_dataset = GLUEMetaValidationDataset(k=8, numTasks=5000)\n",
    "# val_protomaml_loader = data.DataLoader(validation_dataset, num_workers=2)\n",
    "\n",
    "# train_protonet_loader = data.DataLoader(\n",
    "#     meta_ds, num_workers=4)\n",
    "\n",
    "# protomaml_model = train_model(\n",
    "#     ProtoNet,\n",
    "#     train_loader=train_protonet_loader,\n",
    "#     val_loader=val_protomaml_loader,\n",
    "#     metaLearningRate=5e-5, prototypeLearningRate=1e-2, steps=5, batchSize=8, warmupSteps=0\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bc9346",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from prototypes.models.PrototypeMetaModel import PrototypeMetaModel\n",
    "import torch\n",
    "\n",
    "model = PrototypeMetaModel()\n",
    "model_1 = PrototypeMetaModel()\n",
    "\n",
    "for param, param_1 in zip(model.parameters(), model_1.parameters()):\n",
    "    if param.requires_grad:\n",
    "        if param.grad is None:\n",
    "            param.grad = torch.zeros(param_1.data.shape)\n",
    "        param.grad.data += (param.data - param_1.data)\n",
    "        print(param_1.data)\n",
    "        print(param.data)\n",
    "        print(param.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16ae3e1",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
