{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb68d492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aksingh/miniconda3/envs/meta-learned-lines/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset glue (/home/aksingh/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 630.53it/s]\n",
      "Found cached dataset glue (/home/aksingh/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 113.05it/s]\n",
      "Found cached dataset glue (/home/aksingh/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1145.88it/s]\n",
      "Found cached dataset glue (/home/aksingh/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 213.26it/s]\n",
      "Found cached dataset glue (/home/aksingh/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 68.94it/s]\n",
      "Found cached dataset glue (/home/aksingh/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1021.84it/s]\n",
      "Found cached dataset glue (/home/aksingh/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 308.99it/s]\n"
     ]
    }
   ],
   "source": [
    "from training_datasets.GLUEMetaDataset import GLUEMetaDataset\n",
    "from samplers.FewShotEpisodeSampler import FewShotEpisodeSampler\n",
    "from samplers.FewShotEpisodeBatchSampler import FewShotEpisodeBatchSampler\n",
    "import torch.utils.data as data\n",
    "\n",
    "meta_ds = GLUEMetaDataset(k=4,numTasks=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d24829a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_protomaml_sampler = FewShotEpisodeBatchSampler(meta_ds, kShot=4, batchSize=4)\n",
    "\n",
    "train_protomaml_loader = data.DataLoader(\n",
    "    meta_ds, batch_sampler=train_protomaml_sampler, collate_fn=train_protomaml_sampler.getCollateFunction(), num_workers=4)\n",
    "\n",
    "# for i in range(1):\n",
    "#     batch = next(iter(train_protomaml_loader))\n",
    "#     for episode_i in range(len(batch[0])):\n",
    "#         data, labels = batch[0][episode_i], batch[1][episode_i]\n",
    "#         supportSet, supportLabels = data[0:len(data)//2], labels[0:len(data)//2] \n",
    "#         print(supportLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b300d2f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# episodes = []\n",
    "# for i in range(1):\n",
    "#     episodes.append(gm_ds.getTask())\n",
    "# for i in range(len(episodes)):\n",
    "#     classes = len(set(episodes[i][1].tolist()))\n",
    "#     # print(classes)\n",
    "#     print(episodes[i][0], episodes[i][1], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec3922a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from training.models.ProtoFOMAML import ProtoFOMAML\n",
    "\n",
    "# pfomaml = ProtoFOMAML(outerLR=5e-4, innerLR=1e-3, outputLR=1e-2, steps=5, batchSize=16, warmupSteps=0)\n",
    "# pfomaml.training_step(next(iter(train_protomaml_loader)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3670cc53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from samplers.FewShotValidationEpisodeBatchSampler import FewShotValidationEpisodeBatchSampler\n",
    "from samplers.FewShotValidationEpisodeSampler import FewShotValidationEpisodeSampler\n",
    "from validation_datasets.ValidationDataset import ValidationDataset\n",
    "import torch.utils.data as data\n",
    "\n",
    "ds = ValidationDataset()\n",
    "\n",
    "val_protomaml_sampler = FewShotValidationEpisodeBatchSampler(ds, kShot=4)\n",
    "val_protomaml_loader = data.DataLoader(\n",
    "    ds, batch_sampler=val_protomaml_sampler, collate_fn=val_protomaml_sampler.getCollateFunction(), num_workers=1\n",
    ")\n",
    "\n",
    "for i in range(1):\n",
    "    batch = next(iter(val_protomaml_loader))\n",
    "    for episode_i in range(len(batch[0])):\n",
    "        data, labels = batch[0][episode_i], batch[1][episode_i]\n",
    "        supportSet, supportLabels = data[0:len(data)//2], labels[0:len(data)//2] \n",
    "#         print(supportLabels)\n",
    "#         print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ef372a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from training.models.ProtoFOMAML import ProtoFOMAML\n",
    "\n",
    "# pfomaml = ProtoFOMAML(outerLR=5e-4, innerLR=1e-3, outputLR=1e-2, steps=5, batchSize=16, warmupSteps=0)\n",
    "# pfomaml.validation_step(next(iter(val_protomaml_loader)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0cb485",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "/home/aksingh/miniconda3/envs/meta-learned-lines/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:72: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name        | Type               | Params\n",
      "---------------------------------------------------\n",
      "0 | metaLearner | PrototypeMetaModel | 108 M \n",
      "---------------------------------------------------\n",
      "14.4 M    Trainable params\n",
      "94.1 M    Non-trainable params\n",
      "108 M     Total params\n",
      "434.029   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ProtoFOMAML with parameters \"batchSize\":   8\n",
      "\"innerLR\":     0.001\n",
      "\"outerLR\":     0.0005\n",
      "\"outputLR\":    0.01\n",
      "\"steps\":       10\n",
      "\"warmupSteps\": 0\n",
      "Number of labels in the episode are 2 and lines are 1\n",
      "inner loop training loss is 4.673847675323486 and accuracy is 1.0\n",
      "inner loop training loss is 2.0927298069000244 and accuracy is 1.0\n",
      "inner loop training loss is 2.828368663787842 and accuracy is 1.0\n",
      "inner loop training loss is 0.1372455209493637 and accuracy is 1.0\n",
      "inner loop training loss is 0.23103585839271545 and accuracy is 1.0\n",
      "inner loop training loss is 0.0012517105787992477 and accuracy is 1.0\n",
      "inner loop training loss is 1.68084297911264e-05 and accuracy is 1.0\n",
      "inner loop training loss is 2.3841855067985307e-07 and accuracy is 1.0\n",
      "inner loop training loss is 0 and accuracy is 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aksingh/miniconda3/envs/meta-learned-lines/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('inner_loop_training_loss', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inner loop training loss is 0 and accuracy is 1.0\n",
      "outer loop training accuracy is 0.625 and loss is 48.93934631347656\n",
      "Number of labels in the episode are 3 and lines are 1\n",
      "inner loop training loss is 24.792964935302734 and accuracy is 0.5833333333333334\n",
      "inner loop training loss is 16.948206901550293 and accuracy is 0.4166666666666667\n",
      "inner loop training loss is 14.454851627349854 and accuracy is 0.5\n",
      "inner loop training loss is 14.992933869361877 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 18.586313143372536 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 10.356051921844482 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 7.925846420228481 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 7.378769635812205 and accuracy is 0.8333333333333334\n",
      "inner loop training loss is 3.638570427894585 and accuracy is 0.75\n",
      "inner loop training loss is 1.2384074926376272 and accuracy is 1.0\n",
      "outer loop training accuracy is 0.16666666666666666 and loss is 92.51881790161133\n",
      "Number of labels in the episode are 2 and lines are 1\n",
      "inner loop training loss is 4.4351983070373535 and accuracy is 0.875\n",
      "inner loop training loss is 2.450479745864868 and accuracy is 1.0\n",
      "inner loop training loss is 4.974608421325684 and accuracy is 0.5\n",
      "inner loop training loss is 21.711483001708984 and accuracy is 0.5\n",
      "inner loop training loss is 9.271418571472168 and accuracy is 0.5\n",
      "inner loop training loss is 4.755240440368652 and accuracy is 0.5\n",
      "inner loop training loss is 0.7186005711555481 and accuracy is 1.0\n",
      "inner loop training loss is 0.13648496568202972 and accuracy is 1.0\n",
      "inner loop training loss is 0.0924658253788948 and accuracy is 1.0\n",
      "inner loop training loss is 3.8981128454906866e-05 and accuracy is 1.0\n",
      "outer loop training accuracy is 0.75 and loss is 21.781618118286133\n",
      "Number of labels in the episode are 3 and lines are 1\n",
      "inner loop training loss is 21.627439975738525 and accuracy is 0.5\n",
      "inner loop training loss is 14.2713623046875 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 10.261034667491913 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 23.046146512031555 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 6.242206837981939 and accuracy is 0.8333333333333334\n",
      "inner loop training loss is 6.5983874797821045 and accuracy is 0.8333333333333334\n",
      "inner loop training loss is 1.9454028448089957 and accuracy is 0.9166666666666666\n",
      "inner loop training loss is 0.5530555810400983 and accuracy is 1.0\n",
      "inner loop training loss is 0.07407613098621368 and accuracy is 1.0\n",
      "inner loop training loss is 0.003985443152487278 and accuracy is 1.0\n",
      "outer loop training accuracy is 0.3333333333333333 and loss is 79.82307775283698\n",
      "Number of labels in the episode are 2 and lines are 1\n",
      "inner loop training loss is 5.603233337402344 and accuracy is 0.375\n",
      "inner loop training loss is 8.5448579788208 and accuracy is 0.5\n",
      "inner loop training loss is 10.729379653930664 and accuracy is 0.5\n",
      "inner loop training loss is 8.733057022094727 and accuracy is 0.5\n",
      "inner loop training loss is 10.170681953430176 and accuracy is 0.5\n",
      "inner loop training loss is 6.465114116668701 and accuracy is 0.5\n",
      "inner loop training loss is 7.8268351554870605 and accuracy is 0.5\n",
      "inner loop training loss is 6.382923126220703 and accuracy is 0.5\n",
      "inner loop training loss is 3.8420872688293457 and accuracy is 0.625\n",
      "inner loop training loss is 2.562594175338745 and accuracy is 0.875\n",
      "outer loop training accuracy is 0.5 and loss is 12.820749282836914\n",
      "Number of labels in the episode are 2 and lines are 1\n",
      "inner loop training loss is 4.882197380065918 and accuracy is 0.75\n",
      "inner loop training loss is 9.381430625915527 and accuracy is 0.5\n",
      "inner loop training loss is 16.474088668823242 and accuracy is 0.5\n",
      "inner loop training loss is 11.580489158630371 and accuracy is 0.5\n",
      "inner loop training loss is 6.699206829071045 and accuracy is 0.5\n",
      "inner loop training loss is 9.55087661743164 and accuracy is 0.5\n",
      "inner loop training loss is 5.618493556976318 and accuracy is 0.5\n",
      "inner loop training loss is 2.5505950450897217 and accuracy is 0.875\n",
      "inner loop training loss is 1.622739553451538 and accuracy is 1.0\n",
      "inner loop training loss is 0.0347159318625927 and accuracy is 1.0\n",
      "outer loop training accuracy is 0.5 and loss is 16.05757713317871\n",
      "Number of labels in the episode are 2 and lines are 1\n",
      "inner loop training loss is 4.860540866851807 and accuracy is 0.75\n",
      "inner loop training loss is 2.9739322662353516 and accuracy is 0.875\n",
      "inner loop training loss is 21.528133392333984 and accuracy is 0.5\n",
      "inner loop training loss is 10.797856330871582 and accuracy is 0.5\n",
      "inner loop training loss is 7.537442684173584 and accuracy is 0.5\n",
      "inner loop training loss is 4.452678680419922 and accuracy is 0.75\n",
      "inner loop training loss is 2.298334836959839 and accuracy is 0.875\n",
      "inner loop training loss is 14.28991413116455 and accuracy is 0.75\n",
      "inner loop training loss is 3.049029588699341 and accuracy is 0.75\n",
      "inner loop training loss is 1.6982483863830566 and accuracy is 0.875\n",
      "outer loop training accuracy is 0.375 and loss is 24.821197509765625\n",
      "Number of labels in the episode are 2 and lines are 1\n",
      "inner loop training loss is 5.02276611328125 and accuracy is 1.0\n",
      "inner loop training loss is 3.016511917114258 and accuracy is 0.75\n",
      "inner loop training loss is 15.079530715942383 and accuracy is 0.5\n",
      "inner loop training loss is 6.44501256942749 and accuracy is 0.5\n",
      "inner loop training loss is 6.11707067489624 and accuracy is 0.25\n",
      "inner loop training loss is 5.715368270874023 and accuracy is 0.5\n",
      "inner loop training loss is 18.704364776611328 and accuracy is 0.5\n",
      "inner loop training loss is 4.13864278793335 and accuracy is 0.875\n",
      "inner loop training loss is 2.3256211280822754 and accuracy is 0.875\n",
      "inner loop training loss is 1.9848790168762207 and accuracy is 0.875\n",
      "outer loop training accuracy is 0.375 and loss is 20.020721435546875\n",
      "outer loop accuracy is 0.4305555555555556 and total loss is tensor(316.7831, grad_fn=<AddBackward0>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aksingh/miniconda3/envs/meta-learned-lines/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:129: UserWarning: `training_step` returned `None`. If this was on purpose, ignore this warning...\n",
      "  self.warning_cache.warn(\"`training_step` returned `None`. If this was on purpose, ignore this warning...\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels in the episode are 2 and lines are 1\n",
      "inner loop training loss is 5.012779712677002 and accuracy is 0.625\n",
      "inner loop training loss is 5.97076940536499 and accuracy is 0.5\n",
      "inner loop training loss is 16.657569885253906 and accuracy is 0.5\n",
      "inner loop training loss is 12.41330337524414 and accuracy is 0.5\n",
      "inner loop training loss is 5.495307445526123 and accuracy is 0.5\n",
      "inner loop training loss is 6.253486156463623 and accuracy is 0.5\n",
      "inner loop training loss is 7.9357709884643555 and accuracy is 0.5\n",
      "inner loop training loss is 12.170990943908691 and accuracy is 0.625\n",
      "inner loop training loss is 8.039926528930664 and accuracy is 0.5\n",
      "inner loop training loss is 4.899036884307861 and accuracy is 0.75\n",
      "outer loop training accuracy is 0.5 and loss is 10.931307792663574\n",
      "Number of labels in the episode are 3 and lines are 1\n",
      "inner loop training loss is 24.708322525024414 and accuracy is 0.3333333333333333\n",
      "inner loop training loss is 20.747663497924805 and accuracy is 0.4166666666666667\n",
      "inner loop training loss is 22.582218527793884 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 17.529403686523438 and accuracy is 0.3333333333333333\n",
      "inner loop training loss is 8.828119993209839 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 13.313811719417572 and accuracy is 0.75\n",
      "inner loop training loss is 6.555715382099152 and accuracy is 0.8333333333333334\n",
      "inner loop training loss is 2.645646769553423 and accuracy is 0.9166666666666666\n",
      "inner loop training loss is 0.7681159366620705 and accuracy is 1.0\n",
      "inner loop training loss is 0.21033747494220023 and accuracy is 1.0\n",
      "outer loop training accuracy is 0.3333333333333333 and loss is 42.61556128412485\n",
      "Number of labels in the episode are 2 and lines are 1\n",
      "inner loop training loss is 5.073220729827881 and accuracy is 0.875\n",
      "inner loop training loss is 2.6244421005249023 and accuracy is 1.0\n",
      "inner loop training loss is 2.5667953491210938 and accuracy is 0.75\n",
      "inner loop training loss is 12.367112159729004 and accuracy is 0.5\n",
      "inner loop training loss is 0.8033417463302612 and accuracy is 1.0\n",
      "inner loop training loss is 0.05009482428431511 and accuracy is 1.0\n",
      "inner loop training loss is 0.0017356995958834887 and accuracy is 1.0\n",
      "inner loop training loss is 3.218649453629041e-06 and accuracy is 1.0\n",
      "inner loop training loss is 0 and accuracy is 1.0\n",
      "inner loop training loss is 0 and accuracy is 1.0\n",
      "outer loop training accuracy is 0.625 and loss is 58.47607421875\n",
      "Number of labels in the episode are 3 and lines are 1\n",
      "inner loop training loss is 23.345444679260254 and accuracy is 0.08333333333333333\n",
      "inner loop training loss is 19.096195220947266 and accuracy is 0.5833333333333334\n",
      "inner loop training loss is 11.956462979316711 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 19.967106118798256 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 10.66130093485117 and accuracy is 0.75\n",
      "inner loop training loss is 4.312547849491239 and accuracy is 0.8333333333333334\n",
      "inner loop training loss is 5.330335257516708 and accuracy is 0.8333333333333334\n",
      "inner loop training loss is 0.32448893774926546 and accuracy is 1.0\n",
      "inner loop training loss is 0.004314476624131203 and accuracy is 1.0\n",
      "inner loop training loss is 0.00012039679131703451 and accuracy is 1.0\n",
      "outer loop training accuracy is 0.3333333333333333 and loss is 89.9503080539871\n",
      "Number of labels in the episode are 2 and lines are 1\n",
      "inner loop training loss is 5.483606815338135 and accuracy is 0.625\n",
      "inner loop training loss is 7.578703880310059 and accuracy is 0.5\n",
      "inner loop training loss is 13.031601905822754 and accuracy is 0.5\n",
      "inner loop training loss is 8.711788177490234 and accuracy is 0.5\n",
      "inner loop training loss is 10.935704231262207 and accuracy is 0.5\n",
      "inner loop training loss is 5.554286956787109 and accuracy is 0.625\n",
      "inner loop training loss is 3.927154064178467 and accuracy is 0.75\n",
      "inner loop training loss is 5.823038578033447 and accuracy is 0.625\n",
      "inner loop training loss is 2.642160415649414 and accuracy is 0.75\n",
      "inner loop training loss is 0.07544353604316711 and accuracy is 1.0\n",
      "outer loop training accuracy is 0.5 and loss is 19.069076538085938\n",
      "Number of labels in the episode are 2 and lines are 1\n",
      "inner loop training loss is 4.898680686950684 and accuracy is 1.0\n",
      "inner loop training loss is 2.0641350746154785 and accuracy is 1.0\n",
      "inner loop training loss is 4.512331962585449 and accuracy is 0.5\n",
      "inner loop training loss is 11.734441757202148 and accuracy is 0.5\n",
      "inner loop training loss is 0.7186198830604553 and accuracy is 1.0\n",
      "inner loop training loss is 0.053429871797561646 and accuracy is 1.0\n",
      "inner loop training loss is 0.0015257933409884572 and accuracy is 1.0\n",
      "inner loop training loss is 5.841248821525369e-06 and accuracy is 1.0\n",
      "inner loop training loss is 0 and accuracy is 1.0\n",
      "inner loop training loss is 0 and accuracy is 1.0\n",
      "outer loop training accuracy is 0.5 and loss is 48.59323501586914\n",
      "Number of labels in the episode are 2 and lines are 1\n",
      "inner loop training loss is 5.521225929260254 and accuracy is 0.625\n",
      "inner loop training loss is 6.105537414550781 and accuracy is 0.5\n",
      "inner loop training loss is 12.993043899536133 and accuracy is 0.5\n",
      "inner loop training loss is 8.279807090759277 and accuracy is 0.5\n",
      "inner loop training loss is 5.775753974914551 and accuracy is 0.5\n",
      "inner loop training loss is 4.081357955932617 and accuracy is 0.625\n",
      "inner loop training loss is 7.848702430725098 and accuracy is 0.625\n",
      "inner loop training loss is 2.559682846069336 and accuracy is 0.875\n",
      "inner loop training loss is 0.2600744068622589 and accuracy is 1.0\n",
      "inner loop training loss is 0.09137654304504395 and accuracy is 1.0\n",
      "outer loop training accuracy is 0.375 and loss is 18.105449676513672\n",
      "Number of labels in the episode are 3 and lines are 1\n",
      "inner loop training loss is 22.113011837005615 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 15.2319917678833 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 12.486287355422974 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 10.285921812057495 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 7.54417591355741 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 24.58578586578369 and accuracy is 0.75\n",
      "inner loop training loss is 0.8983768606558442 and accuracy is 1.0\n",
      "inner loop training loss is 2.7380907535521146 and accuracy is 0.8333333333333334\n",
      "inner loop training loss is 0.041083965450525284 and accuracy is 1.0\n",
      "inner loop training loss is 0.007452310062831202 and accuracy is 1.0\n",
      "outer loop training accuracy is 0.4166666666666667 and loss is 49.78755393624306\n",
      "outer loop accuracy is 0.4342105263157895 and total loss is tensor(337.5286, grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "Number of labels in the episode are 2 and lines are 1\n",
      "inner loop training loss is 5.0231218338012695 and accuracy is 0.875\n",
      "inner loop training loss is 2.7128055095672607 and accuracy is 1.0\n",
      "inner loop training loss is 3.5260300636291504 and accuracy is 0.75\n",
      "inner loop training loss is 0.3094779849052429 and accuracy is 1.0\n",
      "inner loop training loss is 0.16736000776290894 and accuracy is 1.0\n",
      "inner loop training loss is 0.0020445971749722958 and accuracy is 1.0\n",
      "inner loop training loss is 9.894361028273124e-06 and accuracy is 1.0\n",
      "inner loop training loss is 0 and accuracy is 1.0\n",
      "inner loop training loss is 0 and accuracy is 1.0\n",
      "inner loop training loss is 0 and accuracy is 1.0\n",
      "outer loop training accuracy is 0.5 and loss is 57.97230529785156\n",
      "Number of labels in the episode are 2 and lines are 1\n",
      "inner loop training loss is 5.302608966827393 and accuracy is 0.75\n",
      "inner loop training loss is 2.380455732345581 and accuracy is 1.0\n",
      "inner loop training loss is 0.5288000702857971 and accuracy is 1.0\n",
      "inner loop training loss is 2.032277822494507 and accuracy is 0.875\n",
      "inner loop training loss is 0.022197993472218513 and accuracy is 1.0\n",
      "inner loop training loss is 0.003764811437577009 and accuracy is 1.0\n",
      "inner loop training loss is 5.602831606665859e-06 and accuracy is 1.0\n",
      "inner loop training loss is 0 and accuracy is 1.0\n",
      "inner loop training loss is 0 and accuracy is 1.0\n",
      "inner loop training loss is 0 and accuracy is 1.0\n",
      "outer loop training accuracy is 0.625 and loss is 57.9967041015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels in the episode are 2 and lines are 1\n",
      "inner loop training loss is 5.296738624572754 and accuracy is 0.625\n",
      "inner loop training loss is 2.566908836364746 and accuracy is 0.875\n",
      "inner loop training loss is 11.850149154663086 and accuracy is 0.5\n",
      "inner loop training loss is 4.286468029022217 and accuracy is 0.5\n",
      "inner loop training loss is 1.593632459640503 and accuracy is 0.875\n",
      "inner loop training loss is 0.32952407002449036 and accuracy is 1.0\n",
      "inner loop training loss is 0.04608083888888359 and accuracy is 1.0\n",
      "inner loop training loss is 0.0010287227341905236 and accuracy is 1.0\n",
      "inner loop training loss is 7.152556236178498e-07 and accuracy is 1.0\n",
      "inner loop training loss is 0 and accuracy is 1.0\n",
      "outer loop training accuracy is 0.5 and loss is 46.978233337402344\n",
      "Number of labels in the episode are 2 and lines are 1\n",
      "inner loop training loss is 4.975506782531738 and accuracy is 0.75\n",
      "inner loop training loss is 2.1454739570617676 and accuracy is 1.0\n",
      "inner loop training loss is 3.4351963996887207 and accuracy is 0.75\n",
      "inner loop training loss is 1.2160708904266357 and accuracy is 1.0\n",
      "inner loop training loss is 14.48875617980957 and accuracy is 0.5\n",
      "inner loop training loss is 0.030878866091370583 and accuracy is 1.0\n",
      "inner loop training loss is 0.00024639596813358366 and accuracy is 1.0\n",
      "inner loop training loss is 1.621236515347846e-05 and accuracy is 1.0\n",
      "inner loop training loss is 0 and accuracy is 1.0\n",
      "inner loop training loss is 0 and accuracy is 1.0\n",
      "outer loop training accuracy is 0.625 and loss is 33.259971618652344\n",
      "Number of labels in the episode are 3 and lines are 1\n",
      "inner loop training loss is 24.170920372009277 and accuracy is 0.3333333333333333\n",
      "inner loop training loss is 19.071855545043945 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 19.292100429534912 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 16.787587523460388 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 13.384123533964157 and accuracy is 0.6666666666666666\n",
      "inner loop training loss is 11.853203900158405 and accuracy is 0.8333333333333334\n",
      "inner loop training loss is 8.325683765113354 and accuracy is 0.75\n",
      "inner loop training loss is 9.627315294696018 and accuracy is 0.75\n",
      "inner loop training loss is 2.9565347433081115 and accuracy is 0.9166666666666666\n",
      "inner loop training loss is 0.14403629302978516 and accuracy is 1.0\n",
      "outer loop training accuracy is 0.25 and loss is 47.28015327453613\n",
      "Number of labels in the episode are 2 and lines are 1\n",
      "inner loop training loss is 5.23317813873291 and accuracy is 0.75\n",
      "inner loop training loss is 3.5045599937438965 and accuracy is 1.0\n",
      "inner loop training loss is 6.775174617767334 and accuracy is 0.625\n",
      "inner loop training loss is 9.979643821716309 and accuracy is 0.5\n",
      "inner loop training loss is 4.532051086425781 and accuracy is 0.625\n",
      "inner loop training loss is 0.34057360887527466 and accuracy is 1.0\n",
      "inner loop training loss is 0.02293100208044052 and accuracy is 1.0\n",
      "inner loop training loss is 0.00018596250447444618 and accuracy is 1.0\n",
      "inner loop training loss is 1.0728833785833558e-06 and accuracy is 1.0\n",
      "inner loop training loss is 0 and accuracy is 1.0\n",
      "outer loop training accuracy is 0.5 and loss is 70.43678283691406\n",
      "Number of labels in the episode are 3 and lines are 1\n"
     ]
    }
   ],
   "source": [
    "from training.trainer import train_model\n",
    "\n",
    "protomaml_model = train_model(\n",
    "    ProtoFOMAML,\n",
    "    train_loader=train_protomaml_loader,\n",
    "    val_loader=val_protomaml_loader,\n",
    "    outerLR=5e-4, innerLR=1e-3, outputLR=1e-2, steps=10, batchSize=8, warmupSteps=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94698b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "file_path = \"/home/aksingh/Downloads/version_6/checkpoints/\"\n",
    "\n",
    "for file in os.listdir(file_path):\n",
    "    if file.endswith(\".ckpt\"):\n",
    "        model_path = os.path.join(file_path, file)\n",
    "\n",
    "model = ProtoFOMAML.load_from_checkpoint(model_path, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f15357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.metaLearner)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
