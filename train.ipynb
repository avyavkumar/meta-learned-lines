{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79b5482b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aksingh/miniconda3/envs/meta-learned-lines/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset glue (/home/aksingh/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1032.32it/s]\n",
      "Found cached dataset glue (/home/aksingh/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1448.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from training_datasets.GLUEDataset import GLUEDataset\n",
    "\n",
    "cola = load_dataset('glue','cola')\n",
    "# print(cola)\n",
    "# sst2 = load_dataset('glue','sst2')\n",
    "# print(sst2)\n",
    "mrpc = load_dataset('glue', 'mrpc')\n",
    "# print(mrpc)\n",
    "pt_cola = GLUEDataset([cola, mrpc], 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb229056",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from training_datasets.GLUEMetaDataset import GLUEMetaDataset\n",
    "from samplers.FewShotEpisodeSampler import FewShotEpisodeSampler\n",
    "from samplers.FewShotEpisodeBatchSampler import FewShotEpisodeBatchSampler\n",
    "import torch.utils.data as data\n",
    "\n",
    "# sampler = FewShotEpisodeSampler(pt_cola, kShot=2, nWay=4, shuffle=True)\n",
    "# train_data_loader = data.DataLoader(\n",
    "#     pt_cola,\n",
    "#     batch_sampler=sampler,\n",
    "#     num_workers=1,\n",
    "# )\n",
    "\n",
    "# data, targets = next(iter(train_data_loader))\n",
    "\n",
    "# for i in range(5):\n",
    "#     data, targets = next(iter(train_data_loader))\n",
    "#     print(data)\n",
    "#     print(targets)\n",
    "\n",
    "train_protomaml_sampler = FewShotEpisodeBatchSampler(pt_cola, kShot=3, nWay=4, batchSize=8, shuffle=True)\n",
    "train_protomaml_loader = data.DataLoader(\n",
    "    pt_cola, batch_sampler=train_protomaml_sampler, collate_fn=train_protomaml_sampler.getCollateFunction(), num_workers=1\n",
    ")\n",
    "\n",
    "# for i in range(1):\n",
    "#     batch = next(iter(train_protomaml_loader))\n",
    "#     for episode_i in range(len(batch[0])):\n",
    "#         data, labels = batch[0][episode_i], batch[1][episode_i]\n",
    "#         supportSet, supportLabels = data[0:len(data)//2], labels[0:len(data)//2] \n",
    "#         print(supportLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b300d2f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# episodes = []\n",
    "# for i in range(1):\n",
    "#     episodes.append(gm_ds.getTask())\n",
    "# for i in range(len(episodes)):\n",
    "#     classes = len(set(episodes[i][1].tolist()))\n",
    "#     # print(classes)\n",
    "#     print(episodes[i][0], episodes[i][1], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec3922a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "losses are tensor([0.5351, 0.6120, 0.4798, 0.4584, 0.5762, 0.5325],\n",
      "       grad_fn=<NllLossBackward0>) and loss is 3.193829298019409\n",
      "losses are tensor([0.5298, 0.6090, 0.4751, 0.4469, 0.5679, 0.5224],\n",
      "       grad_fn=<NllLossBackward0>) and loss is 3.1511826515197754\n",
      "losses are tensor([0.5244, 0.6058, 0.4702, 0.4360, 0.5601, 0.5128],\n",
      "       grad_fn=<NllLossBackward0>) and loss is 3.109300136566162\n",
      "losses are tensor([0.5187, 0.6022, 0.4651, 0.4258, 0.5529, 0.5038],\n",
      "       grad_fn=<NllLossBackward0>) and loss is 3.068528890609741\n",
      "losses are tensor([0.5131, 0.5984, 0.4601, 0.4160, 0.5458, 0.4951],\n",
      "       grad_fn=<NllLossBackward0>) and loss is 3.0284793376922607\n",
      "outer loop losses are tensor([0.5269, 0.6717, 0.6292, 0.6731, 0.4846, 0.6795],\n",
      "       grad_fn=<NllLossBackward0>) and loss is 3.665151834487915\n",
      "local param grad is tensor([[ 4.4154e-05, -7.7068e-05,  3.1897e-05,  ...,  1.2258e-04,\n",
      "          5.8701e-05, -4.2431e-05],\n",
      "        [-5.7509e-05, -2.4430e-05, -3.0660e-07,  ..., -1.1096e-05,\n",
      "          4.7193e-05, -1.6433e-05],\n",
      "        [-3.1340e-05,  1.3038e-04,  5.2183e-05,  ..., -4.4482e-05,\n",
      "          9.0214e-06,  4.4046e-05],\n",
      "        ...,\n",
      "        [-7.4657e-05, -1.7671e-04,  8.6475e-05,  ...,  1.8658e-04,\n",
      "          7.2740e-05,  1.5717e-04],\n",
      "        [-4.3563e-06, -2.2671e-05, -2.8229e-04,  ..., -1.3301e-05,\n",
      "          2.1148e-05,  3.8793e-06],\n",
      "        [ 9.3591e-06,  4.9542e-05,  5.6775e-05,  ...,  1.0347e-05,\n",
      "          2.7426e-05, -2.0038e-05]])\n",
      "local param grad is tensor([[ 4.8056e-05, -6.8645e-05,  1.1395e-05,  ...,  8.5335e-05,\n",
      "          2.2072e-05, -3.8966e-05],\n",
      "        [-1.0947e-05, -6.8623e-05, -4.0717e-05,  ..., -3.1907e-05,\n",
      "          1.6126e-05, -1.5519e-05],\n",
      "        [-3.0741e-05,  1.9671e-04,  8.0216e-05,  ..., -2.6602e-06,\n",
      "          3.3728e-05,  4.2810e-05],\n",
      "        ...,\n",
      "        [-2.0111e-04, -2.0821e-04,  2.4253e-04,  ...,  3.5006e-04,\n",
      "          2.2071e-04,  2.9583e-04],\n",
      "        [ 1.1605e-04,  8.8306e-07, -4.3655e-04,  ..., -1.2105e-04,\n",
      "         -7.3248e-05, -3.2122e-05],\n",
      "        [-1.3104e-04,  6.6253e-05,  2.1752e-04,  ...,  1.1426e-04,\n",
      "          9.4353e-05,  3.4192e-05]])\n",
      "meta param grad is tensor([[ 9.2210e-05, -1.4571e-04,  4.3293e-05,  ...,  2.0792e-04,\n",
      "          8.0773e-05, -8.1397e-05],\n",
      "        [-6.8455e-05, -9.3053e-05, -4.1024e-05,  ..., -4.3004e-05,\n",
      "          6.3319e-05, -3.1952e-05],\n",
      "        [-6.2081e-05,  3.2709e-04,  1.3240e-04,  ..., -4.7142e-05,\n",
      "          4.2750e-05,  8.6856e-05],\n",
      "        ...,\n",
      "        [-2.7577e-04, -3.8492e-04,  3.2900e-04,  ...,  5.3664e-04,\n",
      "          2.9345e-04,  4.5300e-04],\n",
      "        [ 1.1170e-04, -2.1788e-05, -7.1884e-04,  ..., -1.3435e-04,\n",
      "         -5.2100e-05, -2.8243e-05],\n",
      "        [-1.2168e-04,  1.1580e-04,  2.7430e-04,  ...,  1.2461e-04,\n",
      "          1.2178e-04,  1.4153e-05]])\n",
      "losses are tensor([0.4027, 0.4647, 0.3380, 0.4432, 0.3657, 0.4289],\n",
      "       grad_fn=<NllLossBackward0>) and loss is 2.443270683288574\n",
      "losses are tensor([0.3862, 0.4524, 0.3276, 0.4289, 0.3439, 0.4038],\n",
      "       grad_fn=<NllLossBackward0>) and loss is 2.342827081680298\n",
      "losses are tensor([0.3720, 0.4395, 0.3167, 0.4144, 0.3247, 0.3819],\n",
      "       grad_fn=<NllLossBackward0>) and loss is 2.2492151260375977\n",
      "losses are tensor([0.3588, 0.4266, 0.3062, 0.4002, 0.3074, 0.3618],\n",
      "       grad_fn=<NllLossBackward0>) and loss is 2.160939931869507\n",
      "losses are tensor([0.3466, 0.4138, 0.2956, 0.3862, 0.2922, 0.3432],\n",
      "       grad_fn=<NllLossBackward0>) and loss is 2.0776479244232178\n",
      "outer loop losses are tensor([0.4343, 0.4912, 0.4594, 0.3721, 0.3202, 0.5194],\n",
      "       grad_fn=<NllLossBackward0>) and loss is 2.5965943336486816\n",
      "local param grad is tensor([[ 6.4572e-05,  7.6758e-05, -1.4630e-04,  ..., -7.1906e-05,\n",
      "         -1.0663e-04,  2.1735e-05],\n",
      "        [ 5.4482e-05,  2.8935e-05, -1.2432e-04,  ..., -1.0339e-05,\n",
      "         -7.1071e-05, -4.6568e-05],\n",
      "        [ 8.5342e-05, -1.8304e-04,  8.4470e-05,  ..., -1.9936e-05,\n",
      "          6.8650e-05,  7.0402e-05],\n",
      "        ...,\n",
      "        [-1.6558e-04, -1.9278e-04,  6.4931e-04,  ...,  4.4657e-04,\n",
      "          4.3425e-04,  4.2017e-05],\n",
      "        [ 2.8526e-04, -9.5278e-05, -9.1657e-04,  ..., -3.4895e-04,\n",
      "         -4.0598e-04, -3.7159e-04],\n",
      "        [-6.9503e-04,  1.0785e-04,  1.4434e-03,  ...,  5.6645e-04,\n",
      "          8.2062e-04,  2.5516e-04]])\n",
      "local param grad is tensor([[ 1.6228e-04,  5.1886e-05, -1.5334e-04,  ..., -1.3537e-04,\n",
      "         -2.5209e-04,  6.9398e-05],\n",
      "        [ 8.0537e-05,  7.6406e-05, -2.4478e-04,  ..., -3.2230e-05,\n",
      "         -2.0849e-04, -7.9261e-05],\n",
      "        [ 1.0317e-04, -3.2812e-04,  9.5370e-05,  ..., -1.6396e-05,\n",
      "          1.8082e-04,  8.9995e-05],\n",
      "        ...,\n",
      "        [-3.9455e-04, -3.9575e-04,  1.1611e-03,  ...,  1.0743e-03,\n",
      "          8.7098e-04,  3.4837e-05],\n",
      "        [ 5.5331e-04, -4.1355e-04, -1.8999e-03,  ..., -4.9077e-04,\n",
      "         -1.0244e-03, -6.3321e-04],\n",
      "        [-1.2760e-03,  3.0409e-04,  3.1351e-03,  ...,  1.2727e-03,\n",
      "          1.7973e-03,  4.6158e-04]])\n",
      "meta param grad is tensor([[ 3.1906e-04, -1.7070e-05, -2.5635e-04,  ...,  6.4481e-07,\n",
      "         -2.7795e-04,  9.7364e-06],\n",
      "        [ 6.6563e-05,  1.2288e-05, -4.1012e-04,  ..., -8.5573e-05,\n",
      "         -2.1624e-04, -1.5778e-04],\n",
      "        [ 1.2643e-04, -1.8407e-04,  3.1224e-04,  ..., -8.3473e-05,\n",
      "          2.9222e-04,  2.4725e-04],\n",
      "        ...,\n",
      "        [-8.3591e-04, -9.7345e-04,  2.1394e-03,  ...,  2.0575e-03,\n",
      "          1.5987e-03,  5.2985e-04],\n",
      "        [ 9.5026e-04, -5.3062e-04, -3.5353e-03,  ..., -9.7406e-04,\n",
      "         -1.4825e-03, -1.0330e-03],\n",
      "        [-2.0927e-03,  5.2774e-04,  4.8528e-03,  ...,  1.9638e-03,\n",
      "          2.7397e-03,  7.3089e-04]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aksingh/miniconda3/envs/meta-learned-lines/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from training.models.ProtoFOMAML import ProtoFOMAML\n",
    "\n",
    "pfomaml = ProtoFOMAML(outerLR=5e-4, innerLR=1e-3, outputLR=1e-2, steps=5, batchSize=16, warmupSteps=0)\n",
    "pfomaml.training_step(next(iter(train_protomaml_loader)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3670cc53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from samplers.FewShotValidationEpisodeBatchSampler import FewShotValidationEpisodeBatchSampler\n",
    "from samplers.FewShotValidationEpisodeSampler import FewShotValidationEpisodeSampler\n",
    "from validation_datasets.ValidationDataset import ValidationDataset\n",
    "import torch.utils.data as data\n",
    "\n",
    "ds = ValidationDataset()\n",
    "\n",
    "val_protomaml_sampler = FewShotValidationEpisodeBatchSampler(ds, kShot=2)\n",
    "val_protomaml_loader = data.DataLoader(\n",
    "    ds, batch_sampler=val_protomaml_sampler, collate_fn=val_protomaml_sampler.getCollateFunction(), num_workers=1\n",
    ")\n",
    "\n",
    "# val_protomaml_loader = data.DataLoader(\n",
    "#     None, batch_sampler=val_protomaml_sampler, num_workers=1\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b555c562",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1]\n",
      "[2, 4, 3, 3, 2, 4]\n",
      "[7, 5, 7, 6, 5, 6]\n",
      "[10, 10, 8, 9, 8, 9]\n",
      "[11, 12, 12, 13, 13, 11]\n",
      "[15, 15, 14, 14]\n",
      "[17, 16, 16, 17]\n",
      "[18, 19, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    batch = next(iter(val_protomaml_loader))\n",
    "#     print(batch)\n",
    "    for episode_i in range(len(batch[0])):\n",
    "        data, labels = batch[0][episode_i], batch[1][episode_i]\n",
    "        supportSet, supportLabels = data[0:len(data)//2], labels[0:len(data)//2]\n",
    "        print(supportLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0cb485",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
